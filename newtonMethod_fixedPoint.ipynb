{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** The function $f(x) = \\cos(x) - x^3 - 2x$ is continuous on $[0,1]$ since it is the sum of functions $\\cos(x)$, $- x^3$ and $- 2x$, which are all continuous on $[0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.cos(x)-(x**3)-(2*x)\n",
    "print(f\"f(0)={f(0)}\")\n",
    "print(f\"f(1)={f(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $f(x)$ is a continuous, $f(0)$ is negative and $f(1)$ is positive, then by IVT there must exist at least one $x \\in [0,1]$ s.t. $f(x)=0$.\n",
    "\n",
    "Note also that $\\forall x \\in \\mathbb{R}$, $\\; f'(x) = -\\sin(x) -3x^2 - 2 < 0 \\rightarrow f$ is strictly decreasing.\n",
    "\n",
    "$\\therefore$ since $f(x)$ is strictly decreasing and by IVT has at least one root in $[0,1]$, this root must be unique $\\quad \\blacksquare$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** If $g$ has a fixed point $x^*$ where $f(x) = 0$ then by the above result we know $x^* \\in [0,1]$. And if $x^*$ can be approximated by $g$ using fixed point iteration then $g$ is a contraction over an interval $[a,b] \\ni x^*$ where $[a,b] \\subseteq [0,1]$. This implies $|g(x^*)| < 1$.\n",
    "\n",
    "However,\n",
    "\\begin{align*}\n",
    "g'(x) &= f'(x) + x'\\\\\n",
    "      &= -\\sin(x) -3x^2 - 2 + 1\\\\\n",
    "      &= -\\sin(x) -3x^2 - 1 \\\\\n",
    "      &\\leq -1 \\quad \\forall x \\in [0,1]\n",
    "\\end{align*}\n",
    "\n",
    "and since $x^* \\in [0,1]$ then $|g'(x^*)| \\geq 1$ which means there is no interval $[a,b] \\ni x^*$ s.t. $g$ is a contraction on $[a,b]$. \n",
    "\n",
    "$\\therefore$ since there exists no interval $[a,b] \\ni x^*$ on which $g$ is a contraction, fixed point iteration cannot be used to approximate the fixed point solution. $\\quad \\blacksquare$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "def g_prime(x):\n",
    "    return -np.sin(x) - 3*x**2 - 1\n",
    "\n",
    "x = np.linspace(-0.5, 1.5, 100)\n",
    "y = g_prime(x)\n",
    "\n",
    "plt.plot(x, y, '-r', label=r'$g\\'(x) = -\\sin(x) - 3x^2 -1$')\n",
    "plt.scatter(x=0, y=g_prime(0), c=\"white\", s=100)\n",
    "plt.annotate(f'(0, {np.round(g_prime(0), 2)})', (0, g_prime(0)), textcoords='offset points', xytext=(-28,-20), ha='center', color=\"white\", fontsize=13)\n",
    "plt.plot(np.linspace(-0.5, 1.5, 10), np.repeat([-1], 10), \"--w\", linewidth=2)\n",
    "plt.plot(np.repeat([0], 10), np.linspace(0, -9, 10), \"--w\", linewidth=2)\n",
    "plt.plot(np.repeat([1], 10), np.linspace(0, -9, 10), \"--w\", linewidth=2)\n",
    "\n",
    "fig = plt.gcf()\n",
    "ax = plt.gca()\n",
    "fig.set_facecolor('#002644')\n",
    "ax.set_facecolor('#002644')\n",
    "for s in ax.spines.values():\n",
    "    s.set_color('white')\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "ax.set_xlabel('x', c='white')\n",
    "ax.set_ylabel('y', c='white')\n",
    "ax.tick_params('both', colors=\"white\")\n",
    "ax.set_xlim([-0.5,1.5])\n",
    "ax.set_ylim([-9, 0])\n",
    "ax.fill_between(np.linspace(0,1, 10), g_prime(np.linspace(0,1, 10)), np.repeat([-1], 10), color='#a58100', alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** We know $\\exists x^* \\in [0,1]$ s.t. $f(x^*)=0$.\n",
    "Thus, we can show\n",
    "\\begin{align*}\n",
    "    f(x^*)                              &= 0 \\\\\n",
    "    \\cos{(x^*)} - (x^*)^3 -2(x^*)       &= 0 \\\\\n",
    "    \\cos{(x^*)}                         &= (x^*)^3 + 2(x^*) \\\\\n",
    "    \\frac{\\cos{(x^*)}}{(x^*)^2 + 2}     &= x^* \\\\\n",
    "    h(x^*)                              &= x^*,\n",
    "\\end{align*}\n",
    "which proves that the root of $f$ is simultaneously the fixed point $h(x^*) = x^*$.\n",
    "\n",
    "The reason we can use $h$ to approximate the solution from any initial point in $[0,1]$ is because $h$ is a contraction on $[0,1]$. We show this as follows,\n",
    "\\begin{align*}\n",
    "    \\frac{d}{dx}h(x)  &= \\frac{d}{dx}\\frac{\\cos{(x)}}{(x^2 + 2)}\\\\\n",
    "    h'(x) &= (-1) \\left[ \\frac{\\sin(x)(x^2 + 2) + \\cos(x)(2x)}{(x^2 + 2)^{2}} \\right]\n",
    "\\end{align*}\n",
    "\n",
    "note that $\\forall x \\in [0,1]$,\n",
    "\\begin{align*}\n",
    "    0 \\leq& \\; \\sin(x) \\; < 1\\\\\n",
    "    0 \\leq& \\; \\sin(x)(x^2 + 2) \\; < (x^2 + 2)\n",
    "\\end{align*}\n",
    "also\n",
    "\\begin{align*}\n",
    "    0 <& \\; \\cos(x) \\; \\leq 1\\\\\n",
    "    0 \\leq& \\; \\cos(x)(2x) \\; \\leq (2x)\n",
    "\\end{align*}\n",
    "which implies\n",
    "\\begin{align*}\n",
    "    \\cos(x)(2x) + \\sin(x)(x^2 + 2) &< (2x) + (x^2 + 2)\\\\\n",
    "                                   &= (x + 1)^{2}\\\\\n",
    "                                   &< (x^2 + 2)^{2}\n",
    "\\end{align*}\n",
    "thus we find that $\\forall x \\in [0,1]$, $\\;|h'(x)| < 1$ and $h'(x) \\leq 0$. \n",
    "\n",
    "Finally, since we now know $h$ is non-increasing on $[0,1]$, we conclude $0 < h(1) \\approx 0.18 \\leq h(x) \\leq h(0) = 0.5 < 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(x):\n",
    "    return np.cos(x)/(x**2 + 2)\n",
    "\n",
    "display(Markdown(rf'$0 < h(1) \\approx {h(1)} \\leq h(x) \\leq h(0) = 0.5 < 1$'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\therefore$ $h$ is a contraction on the interval $[0,1]$ and so fixed point iteration will successfully approximate the solution from any initial point in the interval. $\\quad \\blacksquare$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "x_0 = 0.1\n",
    "x_star = 1\n",
    "while (True):\n",
    "    x_star = h(x_0)\n",
    "    if(np.abs(x_star - x_0) < 1e-15):\n",
    "        break\n",
    "    x_0 = x_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 100)\n",
    "y_h = h(x)\n",
    "y_f = f(x)\n",
    "\n",
    "plt.plot(x, y_h, linestyle='-', color='red', label=r'$h(x) = \\frac{\\cos(x)}{x^2 + 2}$')\n",
    "plt.plot(x, y_f, linestyle='-', color='green', label=r'$f(x) = \\cos(x) - x^2 - 2x$')\n",
    "plt.plot(x, x, linestyle='-', color='orange', label=r'$y = x$')\n",
    "\n",
    "plt.scatter(x=x_star, y=h(x_star), c=\"white\", s=80)\n",
    "plt.annotate(r'($x^*$, $h(x^*)$)', (x_star, h(x_star)), textcoords='offset points', xytext=(-10,20), ha='center', color=\"white\", fontsize=13)\n",
    "plt.scatter(x=x_star, y=0, c=\"white\", s=80)\n",
    "plt.annotate(r'($x^*$, $f(x^*)$)', (x_star, f(x_star)), textcoords='offset points', xytext=(40,15), ha='center', color=\"white\", fontsize=13)\n",
    "plt.plot(np.repeat([x_star], 10), np.linspace(0,h(x_star), 10), linestyle='--', color='white')\n",
    "plt.plot(np.linspace(0,1, 10), np.repeat([0], 10), linestyle='--', color='white')\n",
    "\n",
    "fig = plt.gcf()\n",
    "ax = plt.gca()\n",
    "fig.set_facecolor('#002644')\n",
    "ax.set_facecolor('#002644')\n",
    "for s in ax.spines.values():\n",
    "    s.set_color('white')\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "ax.set_xlabel('x', c='white')\n",
    "ax.set_ylabel('y', c='white')\n",
    "ax.tick_params('both', colors=\"white\")\n",
    "ax.set_ylim([-0.5,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** We begin by using initial value $x_0 = 0.1$, evaluating the first fixed point iterate $x_1 = h(x_0)$ and estimating $\\lambda$ by sampling from the interval $[0,1]$ in order to approximate $\\max\\limits_{x\\in[0,1]} |h'(x)|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_p(x):\n",
    "    return (-(x**2+2)*(np.sin(x))-(2*x)*(np.cos(x))) / (x**2+2)**2\n",
    "\n",
    "lm = np.max(np.abs(h_p(np.linspace(0,1,10000)))) # using 10000 samples in [0,1]\n",
    "x_0 = 0.1\n",
    "x_1 = h(x_0)\n",
    "\n",
    "display(Markdown(rf'$x_0 = {x_0}$'))\n",
    "display(Markdown(rf'$x_1 = {x_1}$'))\n",
    "display(Markdown(rf'$\\lambda = {lm}$'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now approximate the number of iterations required to estimate the fixed point of $h$ within a maximum error threshold of $10^{-2}$ as follows:\n",
    "\\begin{align*}\n",
    "    |x^* - x_k | \\leq& \\; \\frac{\\lambda^{k}}{1-\\lambda} |x_1 - x_0| \\; \\leq \\; 10^{-2}\\\\\n",
    "    \\frac{\\lambda^{k}}{1-\\lambda} |x_1 - x_0| \\leq& \\; 10^{-2}\\\\\n",
    "    \\lambda^{k} \\leq& \\; \\frac{(1-\\lambda)10^{-2}}{|x_1 - x_0 |}\\\\\n",
    "    k \\geq& \\; \\frac{\\ln{ (\\frac{(1-\\lambda)10^{-2}}{|x_1 - x_0 |}) }}{\\ln{\\lambda}} \\quad \\text{noting that $\\ln{\\lambda} < 0 $}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_k = (np.log( (1-lm)*(1e-2) / (np.abs(x_1-x_0))) / np.log(lm))\n",
    "display(Markdown(rf'$k \\geq {max_k}$'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\therefore$ we need at least 6 iterations to compute the fixed point within an absolute error of $10^{-2} \\quad \\blacksquare$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)** Fixed Point Iteration: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_curr = 0.1\n",
    "x_next = h(x_curr)\n",
    "err = np.abs(x_next - x_curr)\n",
    "\n",
    "for k in range(0,6):\n",
    "    display(Markdown(rf'$x_{k} = {x_curr}$'))\n",
    "    display(Markdown(rf'$f(x_{k}) = {f(x_curr)}$'))\n",
    "    display(Markdown(rf'$x_{k+1} = {x_next}$'))\n",
    "    display(Markdown(rf'$|x_{k+1} - x_{k}| = {err}$'))\n",
    "    #updating\n",
    "    x_curr = x_next\n",
    "    x_next = h(x_curr)\n",
    "    err = np.abs(x_next-x_curr)\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f)** We know $f(x) = \\cos(x) - x^3 - 2x$. This implies $f'(x) = -\\sin(x) - 3x^2 - 2$. Thus, we write the Newton-Raphson update step,\n",
    "\n",
    "\\begin{align*}\n",
    "x_{k+1} &= x_k - \\frac{f(x)}{f'(x)}\\\\\n",
    "x_{k+1} &= x_k - \\frac{\\cos(x_k) - x_k^3 - 2x_k}{-\\sin(x_k) - 3x_k^2 - 2}.\n",
    "\\end{align*}\n",
    "\n",
    "and implement the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x):\n",
    "    return x - (np.cos(x)-x**3-2*x) / (-np.sin(x)-3*x**2-2)\n",
    "\n",
    "x_curr = 1\n",
    "x_next = x_curr\n",
    "res = 3\n",
    "k = 0\n",
    "while (res > 1e-2) :\n",
    "    #updating\n",
    "    x_curr = x_next\n",
    "    x_next = step(x_curr)\n",
    "    err = np.abs(x_next-x_curr)\n",
    "    res = np.abs(f(x_curr))\n",
    "    \n",
    "    #printing\n",
    "    display(Markdown(rf'$x_{k} = {x_curr}$'))\n",
    "    display(Markdown(rf'$f(x_{k}) = {f(x_curr)}$'))\n",
    "    display(Markdown(rf'$x_{k+1} = {x_next}$'))\n",
    "    display(Markdown(rf'$|x_{k+1} - x_{k}| = {err}$'))\n",
    "    print(\"-------------------\")\n",
    "    \n",
    "    k+=1\n",
    "    if(k > 100):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**\n",
    "The Newton-Raphson method for solving the nonlinear system of equations $\\mathbf{f}(\\mathbf{x}) = \\mathbf{0}$, where $\\mathbf{f} : \\mathbb{R}^n \\to \\mathbb{R}^n$, is given by the iterative update:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{k+1} = \\mathbf{x}_k - J_{\\mathbf{f}}(\\mathbf{x}_k)^{-1} \\mathbf{f}(\\mathbf{x}_k)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\mathbf{x}_k$ is the current estimate of the root.\n",
    "- $J_{\\mathbf{f}}(\\mathbf{x}_k)$ is the Jacobian matrix of $\\mathbf{f}$ at $\\mathbf{x}_k$, defined as:\n",
    "\n",
    "$$\n",
    "J_{\\mathbf{f}}(\\mathbf{x}) =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial f_1}{\\partial x_1} & \\frac{\\partial f_1}{\\partial x_2} & \\dots & \\frac{\\partial f_1}{\\partial x_n} \\\\\n",
    "\\frac{\\partial f_2}{\\partial x_1} & \\frac{\\partial f_2}{\\partial x_2} & \\dots & \\frac{\\partial f_2}{\\partial x_n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f_n}{\\partial x_1} & \\frac{\\partial f_n}{\\partial x_2} & \\dots & \\frac{\\partial f_n}{\\partial x_n}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- $J_{\\mathbf{f}}(\\mathbf{x}_k)^{-1}$ is the inverse of the Jacobian matrix, assuming it is non-singular.\n",
    "\n",
    "Alternatively, we can avoid the computationally expensive and inaccurate task of finding $J_{\\mathbf{f}}(\\mathbf{x}_k)^{-1}$, solving directly for $\\Delta \\mathbf{x}_k$ in the equation:\n",
    "\n",
    "$$\n",
    "J_{\\mathbf{f}}(\\mathbf{x}_k) \\Delta \\mathbf{x}_k = -\\mathbf{f}(\\mathbf{x}_k)\n",
    "$$\n",
    "\n",
    "where $\\Delta \\mathbf{x}_k = \\mathbf{x}_{k+1} - \\mathbf{x}_k$, and then using $\\Delta \\mathbf{x}_k$ to update $\\mathbf{x}_{k+1}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates and returns jacobian at given x\n",
    "def J(x_k):\n",
    "    x = x_k[0]\n",
    "    y = x_k[1]\n",
    "    \n",
    "    df1dx = (6*x) * (y**2) - 1\n",
    "    df1dy = (6*x**2) * y\n",
    "    \n",
    "    df2dx = (2*x*y)\n",
    "    df2dy = (x**2) - 10*y\n",
    "    \n",
    "    return np.array([[df1dx, df1dy],[df2dx, df2dy]])\n",
    "\n",
    "# vector valued function\n",
    "def f(x_k):\n",
    "    x = x_k[0]\n",
    "    y = x_k[1]\n",
    "    return np.array([\n",
    "        (3*x**2)*(y**2) - x - 1,\n",
    "        (x**2)*(y) - 5*(y**2) - 1\n",
    "    ])\n",
    "\n",
    "# initial point\n",
    "x_curr = np.array([2, 0.5])\n",
    "display(Markdown(rf'$x_{0} = [{x_curr[0]}, {x_curr[1]}]$'))\n",
    "display(Markdown(rf'$res_{0} = {np.linalg.norm(f(x_curr))}$'))\n",
    "print(\"-------------------\")\n",
    "\n",
    "for k in range(0,3):\n",
    "    \n",
    "    J_f = J(x_curr)\n",
    "    f_x = f(x_curr)\n",
    "    delta_x = np.linalg.solve(J_f, -f_x)\n",
    "    x_next = delta_x + x_curr\n",
    "    x_curr = x_next\n",
    "\n",
    "    display(Markdown(rf'$x_{k+1} = [{x_next[0]}, {x_next[1]}]$'))\n",
    "    display(Markdown(rf'$res_{k+1} = {np.linalg.norm(f(x_next))}$'))\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Given the equations,\n",
    "\\begin{align*}\n",
    "    f_1(x,y) &= 3x^2y^2 - x - 1 = 0 \\\\\n",
    "    f_2(x,y) &= x^2y - 5y^2 - 1 = 0  \n",
    "\\end{align*}\n",
    "we can rearrange as follows,\n",
    "\\begin{align*}\n",
    "    g_1(x) &= \\sqrt{\\frac{x+1}{3x^2}} = y\\\\\n",
    "    g_2(y) &= \\sqrt{\\frac{1+5y^2}{y}} = x\n",
    "\\end{align*}\n",
    "\n",
    "Allowing us to write the system $\\mathbf{f}(\\mathbf{x}) = \\mathbf{0}$ as,\n",
    "\n",
    "$$\n",
    "\\mathbf{g}(\\mathbf{x}) =\n",
    "\\begin{bmatrix}\n",
    "g_2(y)\\\\\n",
    "g_1(x)\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\sqrt{\\frac{1+5y^2}{y}}\\\\\n",
    "\\sqrt{\\frac{x+1}{3x^2}}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "x\\\\\n",
    "y\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\mathbf{x}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 0.03\n",
    "x_fixed = x_curr[0]\n",
    "y_fixed = x_curr[1]\n",
    "\n",
    "def g2(y):\n",
    "    return np.sqrt(((5*y**2) + 1) / y)\n",
    "y = np.repeat([y_fixed], 100) + r*np.sin(np.linspace(0, 2*np.pi,100))\n",
    "xs = g2(y)\n",
    "\n",
    "def g1(x):\n",
    "    return np.sqrt((x + 1) / (3 * x**2))\n",
    "x = np.repeat([x_fixed], 100) + r*np.cos(np.linspace(0, 2*np.pi,100))\n",
    "ys = g1(x) \n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(x, y, '-r', label=r'$B_1: \\{\\mathbf{v}\\in\\mathbb{R}^2 \\; | \\; ||\\mathbf{v} - \\mathbf{x}^*||_2 \\leq r \\}$')\n",
    "plt.plot(xs, ys, '-g', label=r'$\\mathbf{g}(B_1)$')\n",
    "plt.scatter(x=x_fixed, y=y_fixed, c='white', s=80)\n",
    "plt.annotate(r'$\\mathbf{x}^* $ ', (x_fixed, y_fixed), textcoords='offset points', xytext=(20,-2), ha='center', color=\"white\", fontsize=13)\n",
    "\n",
    "fig = plt.gcf()\n",
    "ax = plt.gca()\n",
    "fig.set_facecolor('#002644')\n",
    "ax.set_facecolor('#002644')\n",
    "for s in ax.spines.values():\n",
    "    s.set_color('white')\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "ax.set_title(r'$B_1$ vs $\\mathbf{g}(B_1)$', color='white')\n",
    "ax.set_xlabel('x', c='white')\n",
    "ax.set_ylabel('y', c='white')\n",
    "ax.tick_params('both', colors=\"white\")\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm through the above graph that $\\mathbf{g}$ is a contraction on $B_1 \\ni \\mathbf{x}^*$ meaning we can use fixed point iteration to converge to $\\mathbf{x}^*$ from any $\\mathbf{x_0}$ in $B_1 \\quad \\blacksquare$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** The residual of the third iteration of our Newton-Raphson iterations was on the order of $10^{−10}$. The number of iterations required to achieve the same accuracy as three Newton-Raphson iterations can be estimated by solving for $k$ as follows:\n",
    "\n",
    "We use the fixed point functions from part (b),\n",
    "$$\n",
    "g_1(x)=\\sqrt{\\frac{x+1}{3x^2}},\\quad g_2(y)=\\sqrt{\\frac{1+5y^2}{y}}\n",
    "$$\n",
    "to evaluate $D\\mathbf{g}(\\mathbf{x})$ at $\\mathbf{x}^*=(2.1176,0.4814)$,\n",
    "\n",
    "\\begin{align*}\n",
    "D\\mathbf{g}(\\mathbf{x}^*)                                 &= \\begin{bmatrix}0&\\frac{dg_2}{dy}\\\\[1mm]\\frac{dg_1}{dx}&0\\end{bmatrix}\\\\\\\\\n",
    "  \\frac{dg_1}{dx}                                         &=-\\frac{(x+2)}{2\\sqrt{3}\\,x^2\\sqrt{x+1}}\\\\\\\\\n",
    "  \\frac{dg_2}{dy}                                         &=\\frac{5y^2 - 1}{2y^{3/2}\\sqrt{1+5y^2}}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G(x):\n",
    "    return np.array([g2(x[1]), g1(x[0])])\n",
    "x_curr = np.array([2,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_curr[0]\n",
    "y = x_curr[1]\n",
    "dg1dx = -(x + 2) / (2*np.sqrt(3)*x**2*np.sqrt(x+1))\n",
    "dg2dy = (5*y**2 - 1) / (2*y**(3/2) * np.sqrt(1 + 5*y**2))\n",
    "\n",
    "display(Markdown(rf'$\\frac{{dg1}}{{dx}} = {dg1dx}$'))\n",
    "display(Markdown(rf'$\\frac{{dg2}}{{dy}} = {dg2dy}$'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we find the largest singular value (2‑norm) of $D\\mathbf{g}(\\mathbf{x}^*)$. For this diagonal Jacobian we have:\n",
    "$$\n",
    "\\|D\\mathbf{g}(\\mathbf{x}^*)\\|_2\\approx\\max\\Big\\{\\Big|\\frac{dg_1}{dx}\\Big|,\\Big|\\frac{dg_2}{dy}\\Big|\\Big\\}=0.1615\n",
    "$$\n",
    "Thus, we set $\\lambda=\\Big|\\frac{dg_2}{dy}\\Big|$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we find $\\|\\mathbf{x}_1-\\mathbf{x}_{0}\\| = \\|\\mathbf{g}(\\mathbf{x}_0)-\\mathbf{x}_{0}\\|$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps=np.linalg.norm(G(x_curr) - x_curr)\n",
    "eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now solve for $k$ using the second property of contraction and our maximum error threshold,\n",
    "\\begin{align*}\n",
    "\\|\\mathbf{x}^*-\\mathbf{x}_{k+1}\\|          &\\leq \\frac{\\lambda^{k}}{1 - \\lambda}\\|\\mathbf{x}_1-\\mathbf{x}_{0}\\| \\leq 10^{-10}\\\\\n",
    "\\frac{\\lambda^{k}}{1-\\lambda} \\|\\mathbf{x}_1-\\mathbf{x}_{0}\\|  &\\leq \\; 10^{-10}\\\\\n",
    "\\lambda^{k}                                                    &\\leq \\; \\frac{(1-\\lambda)10^{-10}}{\\|\\mathbf{x}_1-\\mathbf{x}_{0}\\|}\\\\\n",
    "k                                                              &\\geq \\; \\frac{\\ln{ (\\frac{(1-\\lambda)10^{-10}}{\\|\\mathbf{x}_1-\\mathbf{x}_{0}\\|}) }}{\\ln{\\lambda}} \\quad \\text{noting that $\\ln{\\lambda} < 0 $}\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = x_curr\n",
    "x_1 = G(x_curr)\n",
    "lm = np.abs(dg2dy)\n",
    "\n",
    "k = np.log( (1-lm)*(1e-10) / eps ) / np.log(lm)\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\therefore$ we need k $\\geq$ 13 iterations to acheive the same accuracy obtained after three Newton-Raphson iterations $\\quad \\blacksquare$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the first three iterates using fixed point iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(rf'$x_{k} = [{x_curr[0]}, {x_curr[1]}]$'))\n",
    "print(\"-------------------\")\n",
    "x_next = x_curr\n",
    "for k in range(0,3):\n",
    "    #updating\n",
    "    x_next = G(x_next)\n",
    "    #printing\n",
    "    display(Markdown(rf'$x_{k+1} = [{x_next[0]}, {x_next[1]}]$'))\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Claim.** The following statements are equivalent for a function $g \\in C^1[a,b]$ and a constant $\\lambda < 1$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "1.&\\quad |g(x) - g(y)| \\le \\lambda \\,|x - y| \\quad \\forall\\, x,y \\in [a,b],\\\\\n",
    "2.&\\quad |g'(x)| \\le \\lambda \\quad \\forall\\, x \\in [a,b].\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Proof**\n",
    "\n",
    "*_(1) $\\rightarrow$ (2):_*\n",
    "\n",
    "\n",
    "Assume $|g(x) - g(y)| \\le \\lambda\\,|x-y|$ for all $x,y \\in [a,b]$.\n",
    "\n",
    "Letting $h = x - y$, we get\n",
    "\n",
    "\\begin{align*}\n",
    "|g(x+h) - g(x)|                    &\\le \\lambda \\, |h| \\\\\\\\\n",
    "\\left|\\frac{g(x+h)-g(x)}{h}\\right| &\\le \\lambda.\n",
    "\\end{align*}\n",
    "\n",
    "Taking the limit as $h \\to 0$,\n",
    "\\begin{align*}\n",
    "\\lim_{h \\to 0}\\left|\\frac{g(x+h)-g(x)}{h}\\right| &\\le \\lim_{h \\to 0}\\lambda.\\\\\n",
    "\\left|\\lim_{h \\to 0}\\frac{g(x+h)-g(x)}{h}\\right| &\\le \\lambda.\\\\\n",
    "\\left|g'(x)\\right| &\\le \\lambda.\\\\\n",
    "\\end{align*}\n",
    "\n",
    "*_(1) $\\leftarrow$ (2):_*\n",
    "\n",
    "Assume $|g'(x)| \\le \\lambda$ for all $x \\in [a,b]$. Let $x,y \\in [a,b]$ with $x \\neq y$. By the Mean Value Theorem, there exists $c$ between $x$ and $y$ such that\n",
    "\n",
    "$$\n",
    "g(y) - g(x) = g'(c)\\,(y-x).\n",
    "$$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$\n",
    "|g(y) - g(x)| = |g'(c)|\\,|y-x| \\le \\lambda \\,|y-x|.\n",
    "$$\n",
    "\n",
    "$\\blacksquare$\n"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Syed Arham Naqvi (100590852)"
   }
  ],
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "subtitle": "Assignment 1 - Math 4020U ",
  "title": "Newton Method and Fixed Point Iteration"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
